{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scattertext to the 2018 State of the Union Speech\n",
    "### Jason S. Kessler: http://www.jasonkessler.com\n",
    "\n",
    "\n",
    "If you are academically inclined, you can cite the accompanying technical article as\n",
    "\n",
    "Jason S. Kessler. Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ. ACL System Demonstrations. Vancouver, BC. 2017. https://arxiv.org/abs/1703.00565\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import scattertext as st\n",
    "import re, io, itertools\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy.en\n",
    "from html import unescape\n",
    "import os, pkgutil, json, urllib, datetime\n",
    "from urllib.request import urlopen\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the database of tweets, parse them, filter out RT's and tweets by devices that Trump probably wasn't using. Label them as before or after election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the last three months of Trump's Tweets\n",
    "* filter them for Tweets written on mobile devices,\n",
    "* filter out non-rewteets\n",
    "\n",
    "### Download historic State of the Union addressses\n",
    "* Keep the ones since 1980\n",
    "* Leave out Trump's 1st address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.concat([pd.read_json('http://www.trumptwitterarchive.com/data/realdonaldtrump/%s.json' % (year))\n",
    "                      for year in range(2017, 2019)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df[tweet_df.source.isin(['Twitter for iPhone', 'Twitter for Android']) \n",
    "                    & (~tweet_df.is_retweet) \n",
    "                    & (tweet_df.created_at > '2017-11-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['parse'] = tweet_df.text.apply(unescape).apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sou_df = pd.read_csv('https://raw.githubusercontent.com/BrianWeinstein/state-of-the-union/master/transcripts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sou_df = (sou_df[(sou_df['date'] > '1980-01-01') \n",
    "                 & (sou_df['date'] != '2017-02-28')]\n",
    "          .rename(columns={'transcript': 'text'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sou_df['parse'] = sou_df.text.apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge two sets together, include metadata for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['metadata'] = tweet_df['created_at']\n",
    "tweet_df['category'] = 'tweet'\n",
    "sou_df['metadata'] = sou_df['president'] + ': ' + sou_df['date']\n",
    "sou_df['category'] = sou_df.president.apply(lambda x: 'trumpsou' if x == 'Donald J. Trump' else 'othersou')\n",
    "df = pd.concat([tweet_df, sou_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trump_state_of_union_2018.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('trump_state_of_union_2018.csv.gz')\n",
    "df['parse'] = df['text'].apply(unescape).apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(df, \n",
    "                                      category_col='category', \n",
    "                                      parsed_col='parse').build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_corpus = corpus.get_unigram_corpus().remove_terms(['&', '#', '/', ':'])\n",
    "tdf = unigram_corpus.get_term_freq_df()\n",
    "unigram_corpus = unigram_corpus.remove_terms(\n",
    "    tdf[(tdf['trumpsou freq'] < 2) & (tdf.sum(axis=1) <= 9)].index\n",
    ")\n",
    "\n",
    "priors = (st.PriorFactory(corpus,\n",
    "                          starting_count=0.01)\n",
    "          .use_all_categories()\n",
    "          .get_priors())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Semiotic Squares\n",
    "* Let's build two semiotic squares for the Trump's language\n",
    "* One will focus on unigrams and caputure stylistic differences\n",
    "* One will focus on phrases (Abram 2016).\n",
    "* The x-axis of the analysis will measure how associated a word or phrase is to the set of Trump's tweets or his 2018 State of the Union address\n",
    "* The y-axis will be how associated a word is to Trump and how associated a word is to \n",
    "* Assocations will be measured through the Log-Odds-Ratio with a Dirichlet Prior (Monroe 2008)\n",
    "\n",
    "### References\n",
    "* Handler, Abram, Matthew J. Denny, Hanna Wallach and Brendan T. Oâ€™Connor. Bag of What? Simple Noun Phrase Extraction for Text Analysis. 2016.\n",
    "* Burt L. Monroe, Michael P. Colaresi, Kevin M. Quinn. Fightin' Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict. Political Analysis. 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_of_the_union_semiotic_square_labels = {\n",
    "        'a': 'Trumpish 2018 State of Union Language',\n",
    "        'not_a': 'Non-Trumpish Language in Tweets',\n",
    "        'b': 'Un-State of the Union-y Language in Trump Tweets',\n",
    "        'not_b': 'Untweet-like, State of the Union-y Language',\n",
    "        'a_and_b': \"Trump\",\n",
    "        'not_a_and_not_b': 'Language from Past Presidents in their States of the Union',\n",
    "        'a_and_not_b': '''2018 State of the Union:<br><span style=\"font-size: 10pt;\">Below: typical State of Union language used by Trump</span>''',\n",
    "        'b_and_not_a': 'Trump Tweets:<br><span style=\"font-size: 10pt;\">Below: langauge about standard State-of-the-Union topics used more in Trump Tweets</span>'   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "semiotic_square = st.SemioticSquare(\n",
    "    unigram_corpus,\n",
    "    category_a='trumpsou',\n",
    "    category_b='tweet',\n",
    "    neutral_categories=['othersou'],\n",
    "    scorer=st.LogOddsRatioInformativeDirichletPrior(priors, alpha_w=10),\n",
    "    labels = state_of_the_union_semiotic_square_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"800\"\n",
       "            src=\"sou_semiotic.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11012eda0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_semiotic_square_explorer(semiotic_square,\n",
    "                                           category_name='Trump-SOUs',\n",
    "                                           not_category_name='Trump-Tweets',\n",
    "                                           x_label='Trump-Speech v Tweets',\n",
    "                                           y_label='Trump v Others',\n",
    "                                           neutral_category_name='Other SOUs',\n",
    "                                           minimum_term_frequency=0,\n",
    "                                           num_terms_semiotic_square=20,\n",
    "                                           axis_scaler=st.Scalers.scale_neg_1_to_1_with_zero_mean,\n",
    "                                           metadata=unigram_corpus._df['metadata'])\n",
    "file_name = 'sou_semiotic.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrasecorpus = st.CorpusFromParsedDocuments(df, \n",
    "                                            feats_from_spacy_doc=st.PhraseMachinePhrases(),\n",
    "                                            category_col='category', \n",
    "                                            parsed_col='parse').build()\n",
    "tdf = phrasecorpus.get_term_freq_df()\n",
    "phrasecorpus = phrasecorpus.remove_terms(\n",
    "    tdf[(tdf['trumpsou freq'] < 2) & (tdf.sum(axis=1) <= 6)].index\n",
    ")\n",
    "\n",
    "priors = (st.PriorFactory(phrasecorpus,\n",
    "                          starting_count=0.01)\n",
    "          .use_all_categories()\n",
    "          .get_priors())\n",
    "\n",
    "semiotic_square_phrase = st.SemioticSquare(\n",
    "    phrasecorpus,\n",
    "    category_a='trumpsou',\n",
    "    category_b='tweet',\n",
    "    neutral_categories=['othersou'],\n",
    "    scorer=st.LogOddsRatioInformativeDirichletPrior(priors, 10),\n",
    "    labels = state_of_the_union_semiotic_square_labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1500\"\n",
       "            height=\"800\"\n",
       "            src=\"sou_semiotic_phrase.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1568286d8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_semiotic_square_explorer(semiotic_square_phrase,\n",
    "                                           pmi_threshold_coefficient=0,\n",
    "                                           minimum_term_frequency=2,\n",
    "                                           category_name='Trump-SOUs',\n",
    "                                           not_category_name='Trump-Tweets',\n",
    "                                           x_label='Trump-Speech v Tweets',\n",
    "                                           y_label='Trump v Others',\n",
    "                                           neutral_category_name='Other SOUs',\n",
    "                                           num_terms_semiotic_square=10,\n",
    "                                           axis_scaler=st.Scalers.scale_neg_1_to_1_with_zero_mean,\n",
    "                                           metadata=phrasecorpus._df['metadata']\n",
    "                                          )\n",
    "file_name = 'sou_semiotic_phrase.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1500, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
