{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8e9acba9-0fd2-4095-a173-551ffa6031d8"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scattertext as st\n",
    "import re\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy.en\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ab1b935-081b-4ec6-9bff-a49d71bc34f0"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.en.English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c887d39c-0d8c-4796-9479-9bfa17122ef3"
    }
   },
   "source": [
    "# Parse debates and create plotting interface\n",
    "The function returns a Pandas data frame consisting of two columns, speaker and statement.  Speaker is the name of the speaker, given in all caps, and statement is the speech made during a particular turn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "28c99899-c109-4cfc-b023-45fdb2070e38"
    }
   },
   "outputs": [],
   "source": [
    "def debate_transcript_to_dataframe(fn, speakers):\n",
    "    lines = open(fn).read().split('\\n')\n",
    "    cur_speaker = None\n",
    "    speaker_start_re = re.compile(r'^([(]?[A-Z][A-Z][A-Z]+):?(.+)$')\n",
    "    transcript = []\n",
    "    cur_statement = ''\n",
    "    cur_speaker = None\n",
    "    for line in lines:\n",
    "        match = speaker_start_re.match(line)\n",
    "        if match:\n",
    "            if match.group(1).startswith('('):\n",
    "                continue\n",
    "            if cur_speaker is not None:\n",
    "                transcript.append({'speaker': cur_speaker, 'statement': cur_statement})\n",
    "            cur_speaker = match.group(1).strip()\n",
    "            cur_statement = match.group(2).strip() + '\\n'\n",
    "            for other_name in speakers:\n",
    "                if other_name+':' in cur_statement:\n",
    "                    cur_statement, other_statement = cur_statement.split(other_name)\n",
    "                    transcript.append({'speaker': cur_speaker, 'statement': cur_statement.strip()})\n",
    "                    transcript.append({'speaker': other_name, 'statement': other_statement.strip()})   \n",
    "        else:\n",
    "            cur_statement += line \n",
    "    df = pd.DataFrame(transcript)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read debates into Pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fe53b41b-fd68-475a-9fc1-5f8464bbe938"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>statement</th>\n",
       "      <th>debate</th>\n",
       "      <th>party</th>\n",
       "      <th>speaker and debate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WALLACE</td>\n",
       "      <td>Good evening from the Thomas and Mack Center a...</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>WALLACE 3rd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WALLACE</td>\n",
       "      <td>This debate is sponsored by the Commission on ...</td>\n",
       "      <td>3rd</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>WALLACE 3rd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                          statement debate  \\\n",
       "0  WALLACE  Good evening from the Thomas and Mack Center a...    3rd   \n",
       "1  WALLACE  This debate is sponsored by the Commission on ...    3rd   \n",
       "\n",
       "       party speaker and debate  \n",
       "0  Moderator        WALLACE 3rd  \n",
       "1  Moderator        WALLACE 3rd  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parties = {'QUIJANO':'Moderator', \n",
    "           'KAINE':'Democratic', \n",
    "           'PENCE':'Republican', \n",
    "           'HOLT':'Moderator', \n",
    "           'CLINTON':'Democratic', \n",
    "           'TRUMP':'Republican',\n",
    "           'COOPER':'Moderator',\n",
    "           'RADDATZ':'Moderator',\n",
    "           'WALLACE':'Moderator'}\n",
    "\n",
    "debate_dfs = {}\n",
    "for info in [\n",
    "    {'debate': '1st', 'fn': 'presidential-debate-2016-09-26.txt', 'participants': ['TRUMP','CLINTON','HOLT']},\n",
    "    {'debate': 'VP', 'fn': 'vp-debate-2016-10-04.txt', 'participants': ['PENCE','KAINE','QUIJANO']},\n",
    "    {'debate': '2nd', 'fn': 'debate-2016-10-09-rush.txt', 'participants': ['TRUMP','CLINTON','COOPER','RADDATZ']},\n",
    "    {'debate': '3rd', 'fn': 'debate-2016-10-19.txt', 'participants': ['TRUMP','CLINTON','WALLACE']}]:\n",
    "    cur_df = debate_transcript_to_dataframe(info['fn'], info['participants'])\n",
    "    cur_df['debate'] = info['debate']\n",
    "    cur_df['party'] = cur_df['speaker'].apply(lambda x: parties[x])\n",
    "    cur_df['speaker and debate']=cur_df['speaker'].apply(lambda x: x + ' ' + info['debate'])\n",
    "    debate_dfs[info['debate']] = cur_df   \n",
    "df_all = pd.concat(debate_dfs.values())\n",
    "df_all.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to draw scatter plot in notebook. \n",
    "Creates a chart from text in a data frame, `df`.  The `category` and `other_category` parameters are the names of the columns we'll compare.  The `category_col` is the column in `df` that contains document categories, and contains `category` and `other_category`.  For example, if `category` is \"TRUMP\", then `category_col` would be \"speaker\". `extra` is append to the file name of the html file produced. \n",
    "\n",
    "We'll look at the rest of the optional parameters later.\n",
    "\n",
    "The function returns an iFrame containing containing the HTML visualization, and as a side-effect writes the visualization to an html file, named `category.lower() + '-' + other_category.lower() + extra + '.html'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0080cb63-dc1a-4f70-aeca-2d8e626b6d95"
    }
   },
   "outputs": [],
   "source": [
    "def draw_corpus(df, corpus, category, other_category, category_col, extra='', scores=None, singleScoreMode=False, minimum_term_frequency=2):\n",
    "    html = st.produce_scattertext_explorer(corpus, \n",
    "                                           category=category, \n",
    "                                           category_name=category.lower() +' Term', \n",
    "                                           not_category_name=other_category.lower() + ' Term',\n",
    "                                           pmi_filter_thresold=2,\n",
    "                                           minimum_term_frequency=minimum_term_frequency,\n",
    "                                           metadata=df['speaker and debate'],\n",
    "                                           scores=scores,\n",
    "                                           width_in_pixels=1000,\n",
    "                                           singleScoreMode=singleScoreMode)\n",
    "    file_name = category.lower() + '-' + other_category.lower() + extra + '.html'\n",
    "    open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "    return IFrame(src=file_name, width = 1200, height=1000)\n",
    "\n",
    "def draw_plot(df, category, other_category, category_col, extra=''):\n",
    "    # Scattertext can only do a one column vs. all analysis.  We're excluding any other speakrs\n",
    "    category_vs_other_df = df[(df[category_col] == category) | (df[category_col] == other_category)]\n",
    "    corpus = st.CorpusFromPandas(category_vs_other_df, \n",
    "                                 category_col = category_col, \n",
    "                                 text_col = 'statement',\n",
    "                                 nlp = nlp).build()\n",
    "    return draw_corpus(category_vs_other_df,  corpus, category, other_category, category_col, extra=extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d7ed314d-13ff-4031-8e6b-e10f243571f7"
    }
   },
   "source": [
    "# Find the top words used by the candidates in the 3rd debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4158f339-c980-4471-be45-f847fcfcf523"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump top terms\n",
      "Index(['hillary', 'bad', 'she wants', 'the border', 'you have', 'justices',\n",
      "       'and she', 'strong', 'outsmarted', 'she 's', 'no idea', 'percent',\n",
      "       'a disaster', 'deals', 'signed', 'report', 'have no', 'the baby',\n",
      "       'our jobs', 'to pay'],\n",
      "      dtype='object', name='term')\n",
      "Clinton top terms\n",
      "Index(['women', 'against', 'kind of', 'that is', 'stand', 'work', 'also',\n",
      "       'most', 'undocumented', 'stand up', 'the debt', 'the kind', 'guns',\n",
      "       'rights', 'new jobs', 'roe', 'in our', 'wade', 'health', 'decisions'],\n",
      "      dtype='object', name='term')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category, other_category, category_col = 'CLINTON', 'TRUMP', 'speaker'\n",
    "debate_3 = st.CorpusFromPandas(data_frame = debate_dfs['3rd'][( debate_dfs['3rd'][category_col] == category) \n",
    "                                                              | ( debate_dfs['3rd'][category_col] == other_category)], \n",
    "                               category_col = category_col, \n",
    "                               text_col = 'statement',\n",
    "                               nlp = nlp).build()\n",
    "\n",
    "term_df = debate_3.get_term_freq_df()\n",
    "term_df['Trump'] = debate_3.get_scaled_f_scores('TRUMP')\n",
    "term_df['Clinton'] = debate_3.get_scaled_f_scores('CLINTON')\n",
    "\n",
    "print('Trump top terms')\n",
    "print(term_df.sort_values(by='Trump', ascending=False).iloc[:20].index)\n",
    "print('Clinton top terms')\n",
    "print(term_df.sort_values(by='Clinton', ascending=False).iloc[:20].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clinton vs. Trump word use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ee828df4-fbe8-468f-931e-185017eb74da"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"clinton-trump.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11968ecc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'CLINTON', 'TRUMP', 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"kaine-pence.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x117eef400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'KAINE', 'PENCE', 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1867f15c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'Democratic', 'Republican', 'party')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize LDA topic model of the debates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, create a corpus of all the 2016 debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dem_rep = df_all[df_all.party.isin({'Democratic', 'Republican'})]\n",
    "corpus = st.CorpusFromPandas(df_dem_rep, \n",
    "                             category_col = 'party', \n",
    "                             text_col = 'statement',\n",
    "                             nlp = nlp).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out bigrams and stopwords from the corpus, making a new one called `corpus_uni_stop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "# remove bigrams and stopwords\n",
    "terms_to_ignore = [term for term \n",
    "                   in corpus._term_idx_store._i2val\n",
    "                   if ' ' in term or \"'\" in term or term in ENGLISH_STOP_WORDS]\n",
    "corpus_uni_stop = corpus.remove_terms(terms_to_ignore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train two, party-specifc topic models and one general model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_models = {}\n",
    "for party in ['Republican', 'Democratic', 'General']:\n",
    "    #subset the term-document matrix to only speech from one paraty or aanother\n",
    "    if party != 'General':\n",
    "        X = corpus_uni_stop._X[corpus_uni_stop._y == corpus_uni_stop.get_categories().index(party),:]\n",
    "    else:\n",
    "        X = corpus_uni_stop._X\n",
    "    lda_models[party] = (LatentDirichletAllocation(n_topics=20, \n",
    "                                                   max_iter=60,\n",
    "                                                   learning_method='online',\n",
    "                                                   learning_offset=50.,\n",
    "                                                   random_state=0)\n",
    "                         .fit(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some General Topics\n",
      "Topic #0:\n",
      "wrong, nuclear, renounced, ambitions, codes, heel, permanently, lift, goal, sanctions\n",
      "Topic #1:\n",
      "puppet, handed, heavy, approach, shared, respectful, dramatically, improved, 2014, 2015\n",
      "Topic #2:\n",
      "plan, jobs, economy, think, debt, want, new, effective, invest, million\n",
      "Topic #3:\n",
      "border, borders, amnesty, open, drugs, strong, need, jobs, unfair, excuse\n",
      "Topic #4:\n",
      "yeah, cybersecurity, doubt, period, surge, speak, explain, 10-year, companies, going\n",
      "Topic #5:\n",
      "stand, court, kind, jobs, behalf, debt, supreme, rights, afraid, senate\n",
      "Topic #6:\n",
      "immigrants, undocumented, mexican, interrupt, ok, criminals, mother, baby, rapists, employers\n",
      "Topic #7:\n",
      "admit, lot, polished, apologize, evening, condemn, agreements, enforce, home, minutes\n",
      "Topic #8:\n",
      "second, gun, amendment, guns, background, comprehensive, checks, loophole, 33,000, conflict\n",
      "Topic #9:\n",
      "japan, saudi, arabia, trade, oh, south, countries, read, energy, germany\n",
      "Topic #10:\n",
      "alicia, machado, fbi, idea, bit, thought, hillary, actually, quite, fourth\n",
      "Topic #11:\n",
      "family, office, faith, wonderful, question, visited, november, opinion, vote, heart\n",
      "Topic #12:\n",
      "ahead, outsmarted, lester, gentlemen, step, gave, generally, longer, movement, owe\n",
      "Topic #13:\n",
      "debunked, hit, nerve, puppet, priorities, moments, money, unfortunate, loophole, ranking\n",
      "Topic #14:\n",
      "approved, completely, removed, scare, appoint, justices, toughest, endorsement, nafta, forced\n",
      "Topic #15:\n",
      "women, right, absolutely, choice, defend, roe, wade, concluded, v., decisions\n",
      "Topic #16:\n",
      "nonsense, crisis, correct, collapse, 15,000, ugh, gee, housing, rooted, storm\n",
      "Topic #17:\n",
      "finish, sentence, seventh, circuit, essentially, jobs, want, decided, plan, borders\n",
      "Topic #18:\n",
      "wait, minute, covered, arms, bear, unfortunately, ground, mischaracterization, rank, precautions\n",
      "Topic #19:\n",
      "people, going, country, donald, said, know, just, want, hillary, clinton\n",
      "\n",
      "Some Republican Topics\n",
      "Topic #0:\n",
      "nuclear, weapons, program, ambitions, renounced, thinks, sanctions, israel, heel, goal\n",
      "Topic #1:\n",
      "cybersecurity, hr, 35,000, 33,000, turned, speak, seventh, surge, circuit, respectful\n",
      "Topic #2:\n",
      "fed, wait, minute, believe, angry, extremely, rates, political, depression, golf\n",
      "Topic #3:\n",
      "meet, excuse, obligations, medicare, stay, social, security, jail, reform, government\n",
      "Topic #4:\n",
      "period, 10-year, companies, unacceptable, canada, use, deals, called, standard, private\n",
      "Topic #5:\n",
      "smart, makes, going, way, business, regulations, cut, big, simple, years\n",
      "Topic #6:\n",
      "baby, saying, ok, based, rip, month, ninth, womb, prior, 15,000\n",
      "Topic #7:\n",
      "certificate, birth, approved, blumenthal, payment, ransom, mcclatchy, satisfied, reporter, pressing\n",
      "Topic #8:\n",
      "wrong, hit, nerve, people, need, chicago, just, years, politicians, order\n",
      "Topic #9:\n",
      "21, afford, spending, japan, century, medal, congressional, endorsing, bargain, recipients\n",
      "Topic #10:\n",
      "wall, hillary, clinton, signed, false, deals, wanted, fourth, absolutely, man\n",
      "Topic #11:\n",
      "yes, knew, created, life, squandered, pro, states, dollars, want, believe\n",
      "Topic #12:\n",
      "telling, gave, fighting, enemy, wonder, pay, play, reach, process, public\n",
      "Topic #13:\n",
      "puppet, removed, offended, money, bring, ca, country, companies, work, thing\n",
      "Topic #14:\n",
      "ahead, gentlemen, office, stepped, oval, step, putin, hardly, fbi, case\n",
      "Topic #15:\n",
      "clinton, hillary, trump, senator, foundation, donald, foreign, taxes, american, thank\n",
      "Topic #16:\n",
      "private, server, refused, turn, hacked, subject, foreign, ugh, senator, executives\n",
      "Topic #17:\n",
      "respond, course, allowed, 2,200, know, draw, bigger, w., rules, like\n",
      "Topic #18:\n",
      "amendment, second, release, justices, finish, audit, appoint, let, audited, interrupt\n",
      "Topic #19:\n",
      "going, people, country, just, know, said, did, look, think, say\n",
      "\n",
      "Some Democratic Topics\n",
      "Topic #0:\n",
      "check, eizenkot, gadi, going, jobs, people, know, president, deals, debt\n",
      "Topic #1:\n",
      "shared, political, contributions, dramatically, improved, 2014, 2015, stronger, bookstore, called\n",
      "Topic #2:\n",
      "donald, people, going, think, want, tax, said, plan, trump, jobs\n",
      "Topic #3:\n",
      "debt, plans, jobs, people, going, wealthy, country, growth, looked, million\n",
      "Topic #4:\n",
      "syria, zone, aleppo, notion, explain, humanitarian, northern, talk, spends, travels\n",
      "Topic #5:\n",
      "17, quoting, trashing, intelligence, civilian, military, court, plan, program, muslims\n",
      "Topic #6:\n",
      "arabia, saudi, japan, terrifying, getting, advocated, korea, countries, taken, said\n",
      "Topic #7:\n",
      "ok., al, wiped, leader, qaida, prosecutor, reasonable, concluded, sorry, going\n",
      "Topic #8:\n",
      "cyber, attacks, weigh, facing, kinds, admit, polished, ok, announced, adversaries\n",
      "Topic #9:\n",
      "read, incorrect, book, actually, time, gadhafi, just, gun, took, taken\n",
      "Topic #10:\n",
      "open, borders, bit, thought, actually, fourth, quite, 11, want, rule\n",
      "Topic #11:\n",
      "want, information, make, let, states, security, training, understands, weapons, apprentice\n",
      "Topic #12:\n",
      "donald, trump, said, know, just, people, nuclear, did, president, putin\n",
      "Topic #13:\n",
      "wrote, book, concluded, responsible, oh, loophole, work, priorities, moments, approach\n",
      "Topic #14:\n",
      "sentence, jeffersonian, antithetical, values, completely, finish, particularly, provoked, tweet, attitude\n",
      "Topic #15:\n",
      "right, office, visited, israeli, espionage, cyberattacks, 17, agencies, military, election\n",
      "Topic #16:\n",
      "jobs, work, information, think, state, long, senator, donald, invest, let\n",
      "Topic #17:\n",
      "proposals, yeah, changes, cause, stranded, referring, repatriation, clock, rates, bringing\n",
      "Topic #18:\n",
      "covered, opinion, lester, ground, mischaracterization, rank, language, know, folks, look\n",
      "Topic #19:\n",
      "border, million, apologize, immigration, deportation, reform, security, nation, school, returns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_words_in_topic(scores, corpus, n_top_words):\n",
    "    return [corpus._term_idx_store.getval(i) for i \n",
    "            in scores.argsort()[:-n_top_words - 1:-1]]\n",
    "\n",
    "def print_some_topics(model):\n",
    "    for topic_idx, topic in list(enumerate(model.components_))[:20]:\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(', '.join(top_words_in_topic(model.components_[topic_idx], corpus_uni_stop, 10)))\n",
    "        \n",
    "    print()\n",
    "print(\"Some General Topics\")\n",
    "print_some_topics(lda_models['General'])\n",
    "print(\"Some Republican Topics\")\n",
    "print_some_topics(lda_models['Republican'])\n",
    "print(\"Some Democratic Topics\")\n",
    "print_some_topics(lda_models['Democratic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in Dem topic 6 ['arabia', 'saudi', 'japan', 'terrifying', 'getting', 'advocated', 'korea', 'countries', 'taken', 'said']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican_dem_topic_6.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1192055f8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx = 6\n",
    "party='Democratic'\n",
    "print('Top terms in Dem topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(df_dem_rep, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in Rep topic 7 ['certificate', 'birth', 'approved', 'blumenthal', 'payment', 'ransom', 'mcclatchy', 'satisfied', 'reporter', 'pressing']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican_rep_topic_7.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x119204438>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx = 7\n",
    "party='Republican'\n",
    "print('Top terms in Rep topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(df_dem_rep, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_rep_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in general topic 3 ['border', 'borders', 'amnesty', 'open', 'drugs', 'strong', 'need', 'jobs', 'unfair', 'excuse']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican_gen_topic_3.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1190749e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_idx = 3\n",
    "party='General'\n",
    "print('Top terms in general topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(df_dem_rep, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_gen_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "39cd7772-3198-4909-bec9-1db20561b287"
    }
   },
   "source": [
    "## Visualizing Word2Vec term similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Score each term in corpus against the word \"job\".  SpaCy includes 300-dimensional word vectors and a cosine-similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms that are most similar to \"job\"\n",
      "['job', 'jobs', 'position', 'role', 'work', 'career', 'duty', 'responsibilities', 'tenure', 'contract']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican_dem_topic_6.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1192019b0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_term = nlp('job')\n",
    "scores=np.array([base_term.similarity(nlp(tok)) \n",
    "                 for tok \n",
    "                 in corpus_uni_stop._term_idx_store._i2val])\n",
    "\n",
    "print('Terms that are most similar to \"%s\"' % base_term)\n",
    "print(top_words_in_topic(scores, corpus_uni_stop, 10))\n",
    "draw_corpus(df_dem_rep, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = scores,\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terms that are most similar to \"wealth\"\n",
      "['wealth', 'vibrancy', 'prosperity', 'fortune', 'trustworthiness', 'acumen', 'income', 'sanctity', 'fullness', 'profits']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican_dem_topic_6.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x119205ac8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_term = nlp('wealth')\n",
    "scores=np.array([base_term.similarity(nlp(tok)) \n",
    "                 for tok \n",
    "                 in corpus_uni_stop._term_idx_store._i2val])\n",
    "\n",
    "print('Terms that are most similar to \"%s\"' % base_term)\n",
    "print(top_words_in_topic(scores, corpus_uni_stop, 10))\n",
    "draw_corpus(df_dem_rep, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = scores,\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "16e5e993-5fcd-4d91-8b32-600843c3c863"
    }
   },
   "source": [
    "# Comare Clinton and Trump's 1st debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e17d391f-ab9e-4e7b-afca-ab8e97f104fc"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(debate_dfs['1st'], 'CLINTON', 'TRUMP', 'speaker', '1st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "957ecfae-dc13-4a29-a353-5afb9a3599fb"
    }
   },
   "source": [
    "# Compare Trump to Pence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c59e1e7f-d845-4af4-83ef-9bd238875ab6"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(df_all, 'TRUMP', 'PENCE', 'speaker', '_trumppence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c2b9b4d9-5680-4b2f-83a6-1bbfb8685a8e"
    }
   },
   "source": [
    "# Compare the 1st to the 2nd debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4a929431-8c4d-493f-b969-d05bf5b21e4c"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(df_all, '1st', '2nd', 'debate', '_1st_vs_2nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str.title = lambda self, x: x[0].upper() + x[1:].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
