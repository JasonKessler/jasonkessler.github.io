{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "8e9acba9-0fd2-4095-a173-551ffa6031d8"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scattertext as st\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import spacy.en\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0ab1b935-081b-4ec6-9bff-a49d71bc34f0"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.en.English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c887d39c-0d8c-4796-9479-9bfa17122ef3"
    }
   },
   "source": [
    "# Parse debates and create plotting interface\n",
    "The function returns a Pandas data frame consisting of two columns, speaker and statement.  Speaker is the name of the speaker, given in all caps, and statement is the speech made during a particular turn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "28c99899-c109-4cfc-b023-45fdb2070e38"
    }
   },
   "outputs": [],
   "source": [
    "def debate_transcript_to_dataframe(fn, speakers):\n",
    "    lines = open(fn).read().split('\\n')\n",
    "    cur_speaker = None\n",
    "    speaker_start_re = re.compile(r'^([(]?[A-Z][A-Z][A-Z]+):?(.+)$')\n",
    "    transcript = []\n",
    "    cur_statement = ''\n",
    "    cur_speaker = None\n",
    "    for line in lines:\n",
    "        match = speaker_start_re.match(line)\n",
    "        if match:\n",
    "            if match.group(1).startswith('('):\n",
    "                continue\n",
    "            if cur_speaker is not None:\n",
    "                transcript.append({'speaker': cur_speaker, 'statement': cur_statement})\n",
    "            cur_speaker = match.group(1).strip()\n",
    "            cur_statement = match.group(2).strip() + '\\n'\n",
    "            for other_name in speakers:\n",
    "                if other_name+':' in cur_statement:\n",
    "                    cur_statement, other_statement = cur_statement.split(other_name)\n",
    "                    transcript.append({'speaker': cur_speaker, 'statement': cur_statement.strip()})\n",
    "                    transcript.append({'speaker': other_name, 'statement': other_statement.strip()})   \n",
    "        else:\n",
    "            cur_statement += line \n",
    "    df = pd.DataFrame(transcript)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read debates into Pandas data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fe53b41b-fd68-475a-9fc1-5f8464bbe938"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>statement</th>\n",
       "      <th>debate</th>\n",
       "      <th>party</th>\n",
       "      <th>speaker and debate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUIJANO</td>\n",
       "      <td>Good evening. From Longwood University in Farm...</td>\n",
       "      <td>VP</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>QUIJANO VP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUIJANO</td>\n",
       "      <td>I'm Elaine Quijano, anchor at CBSN, and corres...</td>\n",
       "      <td>VP</td>\n",
       "      <td>Moderator</td>\n",
       "      <td>QUIJANO VP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speaker                                          statement debate  \\\n",
       "0  QUIJANO  Good evening. From Longwood University in Farm...     VP   \n",
       "1  QUIJANO  I'm Elaine Quijano, anchor at CBSN, and corres...     VP   \n",
       "\n",
       "       party speaker and debate  \n",
       "0  Moderator         QUIJANO VP  \n",
       "1  Moderator         QUIJANO VP  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parties = {'QUIJANO':'Moderator', \n",
    "           'KAINE':'Democratic', \n",
    "           'PENCE':'Republican', \n",
    "           'HOLT':'Moderator', \n",
    "           'CLINTON':'Democratic', \n",
    "           'TRUMP':'Republican',\n",
    "           'COOPER':'Moderator',\n",
    "           'RADDATZ':'Moderator',\n",
    "           'WALLACE':'Moderator'}\n",
    "\n",
    "debate_dfs = {}\n",
    "for info in [\n",
    "    {'debate': '1st', 'fn': 'presidential-debate-2016-09-26.txt', 'participants': ['TRUMP','CLINTON','HOLT']},\n",
    "    {'debate': 'VP', 'fn': 'vp-debate-2016-10-04.txt', 'participants': ['PENCE','KAINE','QUIJANO']},\n",
    "    {'debate': '2nd', 'fn': 'debate-2016-10-09-rush.txt', 'participants': ['TRUMP','CLINTON','COOPER','RADDATZ']},\n",
    "    {'debate': '3rd', 'fn': 'debate-2016-10-19.txt', 'participants': ['TRUMP','CLINTON','WALLACE']}]:\n",
    "    cur_df = debate_transcript_to_dataframe(info['fn'], info['participants'])\n",
    "    cur_df['debate'] = info['debate']\n",
    "    cur_df['party'] = cur_df['speaker'].apply(lambda x: parties[x])\n",
    "    cur_df['speaker and debate']=cur_df['speaker'].apply(lambda x: x + ' ' + info['debate'])\n",
    "    debate_dfs[info['debate']] = cur_df   \n",
    "df_all = pd.concat(debate_dfs.values())\n",
    "df_all.iloc[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to draw scatter plot in notebook. \n",
    "Creates a chart from text in a data frame, `df`.  The `category` and `other_category` parameters are the names of the columns we'll compare.  The `category_col` is the column in `df` that contains document categories, and contains `category` and `other_category`.  For example, if `category` is \"TRUMP\", then `category_col` would be \"speaker\". `extra` is append to the file name of the html file produced. \n",
    "\n",
    "`scores` is an array that \n",
    "\n",
    "The function returns an iFrame containing containing the HTML visualization, and as a side-effect writes the visualization to an html file, named `category.lower() + '-' + other_category.lower() + extra + '.html'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0080cb63-dc1a-4f70-aeca-2d8e626b6d95"
    }
   },
   "outputs": [],
   "source": [
    "def draw_corpus(df, corpus, category, other_category, category_col, extra='', scores=None, singleScoreMode=False, minimum_term_frequency=2):\n",
    "    html = st.produce_scattertext_explorer(corpus, \n",
    "                                           category=category, \n",
    "                                           category_name=category.lower() +' Term', \n",
    "                                           not_category_name=other_category.lower() + ' Term',\n",
    "                                           pmi_filter_thresold=2,\n",
    "                                           minimum_term_frequency=minimum_term_frequency,\n",
    "                                           metadata=df['speaker and debate'],\n",
    "                                           scores=scores,\n",
    "                                           width_in_pixels=1000,\n",
    "                                           singleScoreMode=singleScoreMode)\n",
    "    file_name = category.lower() + '-' + other_category.lower() + extra + '.html'\n",
    "    open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "    return IFrame(src=file_name, width = 1200, height=1000)\n",
    "\n",
    "def draw_plot(df, category, other_category, category_col, extra=''):\n",
    "    # Scattertext can only do a one column vs. all analysis.  We're excluding any other speakrs\n",
    "    category_vs_other_df = df[(df[category_col] == category) | (df[category_col] == other_category)]\n",
    "    corpus = st.CorpusFromPandas(category_vs_other_df, \n",
    "                                 category_col = category_col, \n",
    "                                 text_col = 'statement',\n",
    "                                 nlp = nlp).build()\n",
    "    return draw_corpus(category_vs_other_df,  corpus, category, other_category, category_col, extra=extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d7ed314d-13ff-4031-8e6b-e10f243571f7"
    }
   },
   "source": [
    "# Find the top words used by the candidates in the 3rd debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4158f339-c980-4471-be45-f847fcfcf523"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump top terms\n",
      "Index(['hillary', 'bad', 'she wants', 'you have', 'the border', 'and she',\n",
      "       'justices', 'no idea', 'deals', 'strong', 'outsmarted', 'a disaster',\n",
      "       'she 's', 'signed', 'percent', 'pay up', 'have no', 'start', 'to pay',\n",
      "       'strong borders'],\n",
      "      dtype='object', name='term')\n",
      "Clinton top terms\n",
      "Index(['women', 'kind of', 'against', 'that is', 'stand', 'work', 'most',\n",
      "       'also', 'undocumented', 'rights', 'the debt', 'stand up', 'the kind',\n",
      "       'guns', 'wade', 'roe v.', 'new jobs', 'american', 'health', 'million'],\n",
      "      dtype='object', name='term')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category, other_category, category_col = 'CLINTON', 'TRUMP', 'speaker'\n",
    "debate_3 = st.CorpusFromPandas(data_frame = debate_dfs['3rd'][( debate_dfs['3rd'][category_col] == category) \n",
    "                                                              | ( debate_dfs['3rd'][category_col] == other_category)], \n",
    "                               category_col = category_col, \n",
    "                               text_col = 'statement',\n",
    "                               nlp = nlp).build()\n",
    "\n",
    "term_df = debate_3.get_term_freq_df()\n",
    "term_df['Trump'] = debate_3.get_scaled_f_scores('TRUMP')\n",
    "term_df['Clinton'] = debate_3.get_scaled_f_scores('CLINTON')\n",
    "\n",
    "print('Trump top terms')\n",
    "print(term_df.sort_values(by='Trump', ascending=False).iloc[:20].index)\n",
    "print('Clinton top terms')\n",
    "print(term_df.sort_values(by='Clinton', ascending=False).iloc[:20].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clinton vs. Trump word use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ee828df4-fbe8-468f-931e-185017eb74da"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"clinton-trump.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x118e6ada0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'CLINTON', 'TRUMP', 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"kaine-pence.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ed0620b8>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'KAINE', 'PENCE', 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"1000\"\n",
       "            src=\"democratic-republican.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x117d4bbe0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_plot(df_all, 'Democratic', 'Republican', 'party')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize LDA topic model of the debates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, create a corpus of all the 2016 debates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromPandas(df_all, \n",
    "                             category_col = 'party', \n",
    "                             text_col = 'statement',\n",
    "                             nlp = nlp).build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out bigrams and stopwords from the corpus, making a new one called `corpus_uni_stop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "# remove bigrams and stopwords\n",
    "terms_to_ignore = [term for term \n",
    "                   in corpus._term_idx_store._i2val\n",
    "                   if ' ' in term or \"'\" in term or term in ENGLISH_STOP_WORDS]\n",
    "corpus_uni_stop = corpus.remove_terms(terms_to_ignore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train two, party-specifc topic models and one general model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_models = {}\n",
    "for party in ['Republican', 'Democratic', 'General']:\n",
    "    #subset the term-document matrix to only speech from one paraty or aanother\n",
    "    if party != 'General':\n",
    "        X = corpus_uni_stop._X[corpus_uni_stop._y == corpus_uni_stop.get_categories().index(party),:]\n",
    "    else:\n",
    "        X = corpus_uni_stop._X\n",
    "    lda_models[party] = (LatentDirichletAllocation(n_topics=20, \n",
    "                                                   max_iter=60,\n",
    "                                                   learning_method='online',\n",
    "                                                   learning_offset=50.,\n",
    "                                                   random_state=0)\n",
    "                         .fit(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five General Topics\n",
      "Topic #0:\n",
      "yes, telling, concluded, reasonable, prosecutor, machado, alicia, fine, sorry, taxes\n",
      "Topic #1:\n",
      "stay, protection, washington, plays, 2011, serving, troops, guess, want, iraq\n",
      "Topic #2:\n",
      "security, social, administration, school, wrote, strong, pushing, office, solvent, poverty\n",
      "Topic #3:\n",
      "wait, 17, minute, quoting, apologize, interference, condemn, level, income, median\n",
      "Topic #4:\n",
      "yeah, presidential, gentlemen, debate, commission, evening, topic, debates, welcome, smart\n",
      "\n",
      "First Five Republican Topics\n",
      "Topic #0:\n",
      "program, weapons, nuclear, eliminate, iranian, mountain, choices, path, face, range\n",
      "Topic #1:\n",
      "soldier, freedom, troops, iraqi, zubowski, scott, status, forces, agreement, operation\n",
      "Topic #2:\n",
      "oh, nonsense, children, families, ca, makes, smart, crisis, readily, adopt\n",
      "Topic #3:\n",
      "correct, ugh, fbi, understand, said, change, senator, half, wrong, want\n",
      "Topic #4:\n",
      "yeah, puppet, yes, ought, grade, school, tragedy, essentially, speak, cybersecurity\n",
      "\n",
      "First Five Democratic Topics\n",
      "Topic #0:\n",
      "quoting, mischaracterization, rank, percent, ninety, 17, dramatically, 2014, improved, 2015\n",
      "Topic #1:\n",
      "sentence, finish, say, going, governor, similar, sent, cio, america, washington\n",
      "Topic #2:\n",
      "stand, court, social, security, supreme, rights, solvent, citizens, behalf, forward\n",
      "Topic #3:\n",
      "actually, bit, thought, contributions, political, quite, said, zubowski, correct, understand\n",
      "Topic #4:\n",
      "near, airport, tape, agencies, poverty, level, income, median, going, jobs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def top_words_in_topic(scores, corpus, n_top_words):\n",
    "    return [corpus._term_idx_store.getval(i) for i \n",
    "            in scores.argsort()[:-n_top_words - 1:-1]]\n",
    "\n",
    "def print_first_five_topics(model):\n",
    "    for topic_idx, topic in list(enumerate(model.components_))[:5]:\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(', '.join(top_words_in_topic(model.components_[topic_idx], corpus_uni_stop, 10)))\n",
    "        \n",
    "    print()\n",
    "print(\"First Five General Topics\")\n",
    "print_first_five_topics(lda_models['General'])\n",
    "print(\"First Five Republican Topics\")\n",
    "print_first_five_topics(lda_models['Republican'])\n",
    "print(\"First Five Democratic Topics\")\n",
    "print_first_five_topics(lda_models['Democratic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in Dem topic 10 ['ok.', 'shared', 'make', 'strong', 'alive', 'administration', 'clinton', 'tpp', 'government', 'book']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-0287314bc7f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mminimum_term_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             singleScoreMode=True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-3ab3262df5a9>\u001b[0m in \u001b[0;36mdraw_corpus\u001b[0;34m(df, corpus, category, other_category, category_col, extra, scores, singleScoreMode, minimum_term_frequency)\u001b[0m\n\u001b[1;32m      9\u001b[0m                                            \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            \u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                            singleScoreMode=singleScoreMode)\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother_category\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kesslej/anaconda3/lib/python3.5/site-packages/scattertext-0.0.1.9.8-py3.5.egg/scattertext/__init__.py\u001b[0m in \u001b[0;36mproduce_scattertext_explorer\u001b[0;34m(corpus, category, category_name, not_category_name, protocol, pmi_filter_thresold, minimum_term_frequency, max_terms, filter_unigrams, height_in_pixels, width_in_pixels, max_snippets, max_docs_per_category, metadata, scores, singleScoreMode, term_ranker)\u001b[0m\n\u001b[1;32m    153\u001b[0m                                                             \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                                                             \u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m \t                                                    metadata=metadata)\n\u001b[0m\u001b[1;32m    156\u001b[0m \treturn HTMLVisualizationAssembly(VizDataAdapter(scatter_chart_data),\n\u001b[1;32m    157\u001b[0m                                          \u001b[0mwidth_in_pixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kesslej/anaconda3/lib/python3.5/site-packages/scattertext-0.0.1.9.8-py3.5.egg/scattertext/ScatterChartExplorer.py\u001b[0m in \u001b[0;36mto_dict\u001b[0;34m(self, category, category_name, not_category_name, scores, metadata, max_docs_per_category, transform)\u001b[0m\n\u001b[1;32m     53\u001b[0m \t\t                         transform=percentile_ordinal)\n\u001b[1;32m     54\u001b[0m                 \u001b[0mdocs_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_docs_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_docs_per_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'docs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_docs_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_getter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kesslej/anaconda3/lib/python3.5/site-packages/scattertext-0.0.1.9.8-py3.5.egg/scattertext/ScatterChartExplorer.py\u001b[0m in \u001b[0;36m_get_docs_structure\u001b[0;34m(self, docs_getter, metadata)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_docs_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts_and_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_getter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kesslej/anaconda3/lib/python3.5/site-packages/scattertext-0.0.1.9.8-py3.5.egg/scattertext/DocsAndLabelsFromCorpus.py\u001b[0m in \u001b[0;36mget_labels_and_texts_and_meta\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# type: (np.array) -> dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels_and_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "topic_idx = 10\n",
    "party='Democratic'\n",
    "print('Top terms in Dem topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(clinton_trump_df, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topic_idx = 4\n",
    "party='Republican'\n",
    "print('Top terms in Rep topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(clinton_trump_df, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_idx = 1\n",
    "party='General'\n",
    "print('Top terms in general topic %s' % topic_idx, \n",
    "      top_words_in_topic(lda_models[party].components_[topic_idx], corpus_uni_stop, 10))\n",
    "draw_corpus(clinton_trump_df, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = lda_models[party].components_[topic_idx],\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "39cd7772-3198-4909-bec9-1db20561b287"
    }
   },
   "source": [
    "## Visualizing Word2Vec term similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "### Score each term in corpus against the word \"job\".  SpaCy includes 300-dimensional word vectors and a cosine-similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_term = nlp('job')\n",
    "scores=np.array([base_term.similarity(nlp(tok)) \n",
    "                 for tok \n",
    "                 in corpus_uni_stop._term_idx_store._i2val])\n",
    "\n",
    "print('Terms that are most similar to \"%s\"' % base_term)\n",
    "print(top_words_in_topic(scores, corpus_uni_stop, 10))\n",
    "draw_corpus(clinton_trump_df, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = scores,\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_term = nlp('wealth')\n",
    "scores=np.array([base_term.similarity(nlp(tok)) \n",
    "                 for tok \n",
    "                 in corpus_uni_stop._term_idx_store._i2val])\n",
    "\n",
    "print('Terms that are most similar to \"%s\"' % base_term)\n",
    "print(top_words_in_topic(scores, corpus_uni_stop, 10))\n",
    "draw_corpus(clinton_trump_df, \n",
    "            corpus_uni_stop, \n",
    "            'Democratic', \n",
    "            'Republican', \n",
    "            'party', \n",
    "            extra='_dem_topic_%s'%(topic_idx), \n",
    "            scores = scores,\n",
    "            minimum_term_frequency=1,\n",
    "            singleScoreMode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "16e5e993-5fcd-4d91-8b32-600843c3c863"
    }
   },
   "source": [
    "# Comare Clinton and Trump's 1st debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "e17d391f-ab9e-4e7b-afca-ab8e97f104fc"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(debate_dfs['1st'], 'CLINTON', 'TRUMP', 'speaker', '1st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "957ecfae-dc13-4a29-a353-5afb9a3599fb"
    }
   },
   "source": [
    "# Compare Trump to Pence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c59e1e7f-d845-4af4-83ef-9bd238875ab6"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(df_all, 'TRUMP', 'PENCE', 'speaker', '_trumppence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c2b9b4d9-5680-4b2f-83a6-1bbfb8685a8e"
    }
   },
   "source": [
    "# Compare the 1st to the 2nd debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4a929431-8c4d-493f-b969-d05bf5b21e4c"
    }
   },
   "outputs": [],
   "source": [
    "draw_plot(df_all, '1st', '2nd', 'debate', '_1st_vs_2nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str.title = lambda self, x: x[0].upper() + x[1:].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
