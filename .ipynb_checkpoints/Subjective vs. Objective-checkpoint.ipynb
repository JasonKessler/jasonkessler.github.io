{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scattertext as ST\n",
    "import tarfile, urllib, io\n",
    "import pandas as pd\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''From Bo Pang's website: https://www.cs.cornell.edu/people/pabo/movie-review-data/\n",
    "\n",
    "Data from:\n",
    "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization \n",
    "Based on Minimum Cuts'', Proceedings of the ACL, 2004\n",
    "\n",
    "Read remote tarball\n",
    "'''\n",
    "SUBJECTIVITY_URL = 'http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz'\n",
    "data = io.BytesIO(urllib.request.urlopen(SUBJECTIVITY_URL).read())\n",
    "tarball = tarfile.open(fileobj=data, mode = 'r:gz')\n",
    "readme = tarball.extractfile('subjdata.README.1.0').read()\n",
    "quote = tarball.extractfile('quote.tok.gt9.5000').read()\n",
    "plot = tarball.extractfile('plot.tok.gt9.5000').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart and alert , thirteen conversations about one thing is a small gem . ',\n",
       " 'color , musical bounce and warm seas lapping on island shores . and just enough science to send you home thinking . ',\n",
       " 'it is not a mass-market entertainment but an uncompromising attempt by one artist to think about another . ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examples of subjective sentences in corpus\n",
    "quote.decode('utf-8', errors='ignore').split('\\n')[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Construct subjective vs. objective pandas dataframe, \n",
    "treating review quotes as subjective, and plot points as objective.\n",
    "'''\n",
    "df = pd.DataFrame(\n",
    "    [{'text': text.strip(), 'label': 'subjective'} for text \n",
    "     in quote.decode('utf-8', errors='ignore').split('\\n')] \n",
    "    + [{'text': text.strip(), 'label': 'objective'} for text \n",
    "       in plot.decode('utf-8', errors='ignore').split('\\n')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Convert Pandas dataframe to a term-document matrix, indicating\n",
    "the category column is \"label\" and the text column name is \"text\".\n",
    "'''\n",
    "\n",
    "term_doc_mat = ST.TermDocMatrixFromPandas(data_frame = df, \n",
    "                                          category_col = 'label', \n",
    "                                          text_col = 'text',\n",
    "                                          # Note: use nlp=spacy.en.English() for text that's not pre-tokenized\n",
    "                                          nlp = ST.fast_but_crap_nlp \n",
    "                                         ).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Filter out bigrams with PMI < 6 (ngram length * 3) and unigrams and \n",
    "bigrams that occur less than 10 times.\n",
    "'''\n",
    "filtered_term_doc_mat = (ST.TermDocMatrixFilter(pmi_threshold_coef = 3,\n",
    "                                                min_freq = 10)\n",
    "                         .filter(term_doc_mat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"subj_obj_scatter.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x119ea5710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assemble data for the scatter chart, and put it in HTML\n",
    "'''\n",
    "scatter_chart_data = (ST.ScatterChart(filtered_term_doc_mat)\n",
    "                      .to_dict('objective',\n",
    "                               category_name='Objective',\n",
    "                               not_category_name='Subjective'))\n",
    "viz_data_adapter = ST.viz.VizDataAdapter(scatter_chart_data)\n",
    "html = ST.viz.HTMLVisualizationAssembly(viz_data_adapter).to_html()\n",
    "\n",
    "# Hack to display HTML with D3 in Jupyter Notebook\n",
    "open('subj_obj_scatter.html', 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src='subj_obj_scatter.html', width = 1000, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>background</th>\n",
       "      <th>Log Posterior Mean Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doesn</th>\n",
       "      <td>176.0</td>\n",
       "      <td>1101832.0</td>\n",
       "      <td>6.972770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isn</th>\n",
       "      <td>125.0</td>\n",
       "      <td>1345149.0</td>\n",
       "      <td>6.392687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discovers</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1974534.0</td>\n",
       "      <td>5.356073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cinematic</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1255895.0</td>\n",
       "      <td>5.091466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filmmaker</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1493747.0</td>\n",
       "      <td>5.063639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cannot</th>\n",
       "      <td>29.0</td>\n",
       "      <td>88737.0</td>\n",
       "      <td>4.860555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filmmaking</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1061519.0</td>\n",
       "      <td>4.768377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thriller</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5364843.0</td>\n",
       "      <td>4.722203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>didn</th>\n",
       "      <td>32.0</td>\n",
       "      <td>850882.0</td>\n",
       "      <td>4.648173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filmmakers</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1657073.0</td>\n",
       "      <td>4.629892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>229.0</td>\n",
       "      <td>22993280.0</td>\n",
       "      <td>4.591236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quirky</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1436076.0</td>\n",
       "      <td>4.553131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documentary</th>\n",
       "      <td>113.0</td>\n",
       "      <td>10429008.0</td>\n",
       "      <td>4.547708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>1006.0</td>\n",
       "      <td>116097842.0</td>\n",
       "      <td>4.512189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertaining</th>\n",
       "      <td>75.0</td>\n",
       "      <td>6330073.0</td>\n",
       "      <td>4.503101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mysterious</th>\n",
       "      <td>65.0</td>\n",
       "      <td>5252752.0</td>\n",
       "      <td>4.483029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decides</th>\n",
       "      <td>58.0</td>\n",
       "      <td>4588774.0</td>\n",
       "      <td>4.447191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performances</th>\n",
       "      <td>94.0</td>\n",
       "      <td>9272429.0</td>\n",
       "      <td>4.417802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learns</th>\n",
       "      <td>40.0</td>\n",
       "      <td>2570984.0</td>\n",
       "      <td>4.390325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasn</th>\n",
       "      <td>20.0</td>\n",
       "      <td>76625.0</td>\n",
       "      <td>4.352190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              corpus   background  Log Posterior Mean Ratio\n",
       "doesn          176.0    1101832.0                  6.972770\n",
       "isn            125.0    1345149.0                  6.392687\n",
       "discovers       70.0    1974534.0                  5.356073\n",
       "cinematic       49.0    1255895.0                  5.091466\n",
       "filmmaker       51.0    1493747.0                  5.063639\n",
       "cannot          29.0      88737.0                  4.860555\n",
       "filmmaking      37.0    1061519.0                  4.768377\n",
       "thriller        78.0    5364843.0                  4.722203\n",
       "didn            32.0     850882.0                  4.648173\n",
       "filmmakers      39.0    1657073.0                  4.629892\n",
       "comedy         229.0   22993280.0                  4.591236\n",
       "quirky          35.0    1436076.0                  4.553131\n",
       "documentary    113.0   10429008.0                  4.547708\n",
       "film          1006.0  116097842.0                  4.512189\n",
       "entertaining    75.0    6330073.0                  4.503101\n",
       "mysterious      65.0    5252752.0                  4.483029\n",
       "decides         58.0    4588774.0                  4.447191\n",
       "performances    94.0    9272429.0                  4.417802\n",
       "learns          40.0    2570984.0                  4.390325\n",
       "hasn            20.0      76625.0                  4.352190"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Display unigrams most characteristic of corpus against all of English that aren't unique to it.\n",
    "\n",
    "Note: \"doesn\", \"isn\", and \"didn\" are a result of the pre-tokenization of the corpus.\n",
    "'''\n",
    "characteristic_terms = term_doc_mat.get_posterior_mean_ratio_scores_vs_background()\n",
    "characteristic_terms[characteristic_terms['background'] > 0].iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
